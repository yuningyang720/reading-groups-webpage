<!DOCTYPE html>
<html>
<head>
    <title>UCLA TrustworthyAI Lab NLP Reading Group</title>
    <link rel="stylesheet" type="text/css" href="style.css">
</head>
<body>
    <header>
        <h1>UCLA TrustworthyAI Lab NLP Reading Group</h1>
    </header>

    <main>
        <h2>Welcome to the UCLA TrustworthyAI Lab NLP Reading Group!</h2>
        <p>Join us on our journey through the fascinating world of Natural Language Processing.</p>
        
        <h3>Group Members</h3>
        <ul>
            <li><b>Advisor Prof. Guang Cheng</b></li>
            <li><b>Co-Advisor Prof. Sheng Wang</b></li>
            <li>Jiaxin Yang</li>
            <li>Minrui Gui</li>
            <li>Zixiang (Jerry) Ji</li>
            <li>Ryan</li>
            <li>Jiacheng</li>
            <li>Xiaofeng</li>
            <li>Matthew</li>
            <li>Yuning Yang</li>
            <li>Rohan</li>
            <li>Yuantong Li</li>
            <li>Yijin Hua</li>
            <li>George Luan</li>
            <li>Shuang Wu</li>
            <li>Chi-Hua Wang</li>
        </ul>

        <h3>Reading List</h3>
        <ul>
            <li><a href="https://arxiv.org/abs/2303.14070">ChatDoctor: A Medical Chat Model Fine-tuned on LLaMA Model using Medical Domain Knowledge</a></li>
            <li><a href="https://arxiv.org/abs/2305.11206">LIMA: Less Is More for Alignment</a></li>
            <li><a href="https://arxiv.org/abs/2304.06975">HuaTuo: Tuning LLaMA Model with Chinese Medical Knowledge</a></li>
            <li><a href="https://arxiv.org/abs/2212.13138">Large Language Models Encode Clinical Knowledge</a></li>
            <li><a href="https://arxiv.org/abs/2304.14454">PMC-LLaMA: Further Finetuning LLaMA on Medical Papers</a></li>
            <li><a href="https://arxiv.org/abs/2305.07804">Dr. LLaMA: Improving Small Language Models on PubMedQA via Generative Data Augmentation</a></li>
            <li><a href="https://arxiv.org/abs/2208.07339">LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale</a></li>
            <li><a href="https://arxiv.org/abs/2212.08073">Constitutional AI: Harmlessness from AI Feedback</a></li>
            <li><a href="https://arxiv.org/abs/2301.13688">The Flan Collection: Designing Data and Methods for Effective Instruction Tuning</a></li>
            <li><a href="https://arxiv.org/pdf/1909.01066">Language Models as Knowledge Bases?</a></li>
        </ul>

        <h3>Schedule</h3>
        <p>06/19 - 09/11 Every Monday 9:30 - 10:30AM 11:00 - 12:00AM </p>

        <h3>Location</h3>
        <p>MS 8359</p>

    </main>

    <footer>
        <p>&copy; 2023 UCLA Trustworthy AI NLP Reading Group. All rights
