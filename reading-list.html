<!DOCTYPE html>
<html>
<head>
    <title>NLP Reading Group - Reading List</title>
    <link rel="stylesheet" type="text/css" href="read_style.css">
</head>
<body>
    <header>
        <h1>NLP Reading Group</h1>
        <nav>
            <ul>
                <li><a href="index.html">Home</a></li>
                <li><a href="reading-list.html">Reading List</a></li>
                <li><a href="schedule.html">Schedule</a></li>
                <li><a href="about.html">About Us</a></li>
                <li><a href="contact.html">Contact</a></li>
            </ul>
        </nav>
    </header>

    <main class="container">
        <h2>Reading List</h2>
        <ul>
            <li>ChatDoctor: A Medical Chat Model Fine-tuned on LLaMA Model using Medical Domain Knowledge</li>
            <li>LIMA: Less Is More for Alignment</li>
            <li>HuaTuo: Tuning LLaMA Model with Chinese Medical Knowledge</li>
            <li>Large Language Models Encode Clinical Knowledge</li>
            <li>PMC-LLaMA: Further Finetuning LLaMA on Medical Papers</li>
            <li>Dr. LLaMA: Improving Small Language Models on PubMedQA via Generative Data Augmentation</li>
            <li>LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale</li>
            <li>Constitutional AI: Harmlessness from AI Feedback</li>
            <li>The Flan Collection: Designing Data and Methods for Effective Instruction Tuning</li>
        </ul>
    </main>

    <footer>
        <p>&copy; 2023 NLP Reading Group. All rights reserved.</p>
    </footer>
</body>
</html>
